{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# KNN Classification and Imputation: Cell Phone Churn Data\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will practice using KNN for classification (and a little bit for regression as well).\n",
    "\n",
    "The dataset is one on \"churn\" in cell phone plans. It has information on the usage of the phones by different account holders and whether or not they churned or not.\n",
    "\n",
    "Our goal is to predict whether a user will churn or not based on the other features.\n",
    "\n",
    "We will also be using the KNN model to **impute** missing data. There are a couple of columns in the dataset with missing values, and we can build KNN models to predict what those missing values will most likely be. This is a more advanced imputation method than just filling in the mean or median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the cell phone \"churn\" data containing some missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn = pd.read_csv('../../datasets/churn_missing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the data. What columns have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# about 12% ofvmail plan & message are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.intl_plan.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.vmail_plan.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Note: DC is being counted as a state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert the `vmail_plan` and `intl_plan` colums to binary integer columns.\n",
    "\n",
    "Make sure that if a value is missing that you don't fill it in with a new value! Preserve the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn.loc[:,'vmail_plan'] = churn.vmail_plan.map(lambda x: 1 if x == 'yes' else 0 if x == 'no' else x)\n",
    "churn.loc[:,'intl_plan'] = churn.intl_plan.map(lambda x: 1 if x == 'yes' else 0 if x == 'no' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create dummy coded columns for state and concatenate it to the churn dataset.\n",
    "\n",
    "> **Remember:** You will need to leave out one of the state dummy coded columns to serve as the \"reference\" column since we will be using these for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states = pd.get_dummies(churn.state, drop_first=True)\n",
    "states.head(3)\n",
    "# drop_first removed Alaska(AK) from being converted to a dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(churn.state.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "churn = pd.concat([churn, states], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a version of the churn data that has no missing values.\n",
    "\n",
    "Calculate the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn_nona = churn.dropna()\n",
    "churn_nona.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a target vector and predictor matrix.\n",
    "\n",
    "- Target should be the `churn` column.\n",
    "- Predictor matrix should be all columns except `area_code`, `state`, and `churn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X =churn_nona.drop(['area_code','state','churn'], axis =1)\n",
    "y = churn_nona.churn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculate the baseline accuracy for `churn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "churn_nona.churn.mean()\n",
    "# Less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "baseline = 1. - churn_nona.churn.mean()\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cross-validate a KNN model predicting `churn`. \n",
    "\n",
    "- Number of neighbors should be 5.\n",
    "- Make sure to standardize the predictor matrix.\n",
    "- Set cross-validation folds to 10.\n",
    "\n",
    "Report the mean cross-validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn, Xs, y, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Iterate from k=1 to k=49 (only odd k) and cross-validate the accuracy of the model for each.\n",
    "\n",
    "Plot the cross-validated mean accuracy for each score. What is the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "k_values = list(range(1,50,2))\n",
    "accs = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, Xs, y, cv=10)\n",
    "    accs.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(k_values, accs, lw=3)\n",
    "plt.show()\n",
    "\n",
    "print(np.max(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# looks like there is a peak at about k=7 and then levels out after k=17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Imputing with KNN\n",
    "\n",
    "K-Nearest Neighbors can be used to impute missing values in datasets. What we will do is estimate the most likely value for the missing data based on a KNN model.\n",
    "\n",
    "We have two columns with missing data:\n",
    "- `vmail_plan`\n",
    "- `vmail_message`\n",
    "\n",
    "**10.A: Create two subsets of the churn dataset: one without missing values for `vmail_plan` and `vmail_message`, and one with the missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "missing_cols = ['vmail_plan','vmail_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:57:55.151282Z",
     "start_time": "2020-07-05T05:57:54.989009Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "impute_missing = churn.loc[churn.vmail_plan.isna(), :]\n",
    "impute_valid = churn.loc[~churn.vmail_plan.isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will impute values for `vmail_plan`. This is a categorical column and so we will impute using classification (predicting whether the plan is yes or no, 1 vs. 0).\n",
    "\n",
    "**10.B: Create a target that is `vmail_plan` and predictor matrix that is all columns except `state`, `area_code`, `churn`, `vmail_plan`, and `vmail_message`.**\n",
    "\n",
    "> **Note:** We don't include the `churn` variable in the model to impute. Why? We are imputing these missing values so that we can use the rows to predict churn with more data afterwards. If we imputed with churn as a predictor then we would be cheating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "impute_cols = [c for c in impute_valid.columns if not c in ['state','area_code','churn']+missing_cols]\n",
    "y = impute_valid.vmail_plan.values\n",
    "X = impute_valid[impute_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.C: Standardize the predictor matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.D: Find the best K for predicting `vmail_plan`.**\n",
    "\n",
    "You may want to write a function for this. What is the accuracy for predicting `vmail_plan` at the best K? What is the baseline accuracy for `vmail_plan`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def find_best_k_cls(X, y, k_min=1, k_max=51, step=2, cv=5):\n",
    "    k_range = list(range(k_min, k_max+1, step))\n",
    "    accs = []\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=cv)\n",
    "        accs.append(np.mean(scores))\n",
    "    print(np.max(accs), np.argmax(k_range))\n",
    "    return np.argmax(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "find_best_k_cls(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "impute_valid.vmail_plan.mean()\n",
    "# less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vmail_plan_baseline = 1. - impute_valid.vmail_plan.mean()\n",
    "print(vmail_plan_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# we can already see that out calculated baseline is practically\n",
    "# identical to the best CV score which leads us down the path\n",
    "# to believe that there would be very little knowledge gain from\n",
    "# said model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.E: Fit a `KNeighborsClassifier` with the best number of neighbors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.F: Predict the missing `vmail_plan` values using the subset of the data where it is misssing.**\n",
    "\n",
    "You will need to:\n",
    "1. Create a new predictor matrix using the same predictors but from the missing subset of data.\n",
    "- Standardize this predictor matrix *using the StandardScaler object fit on the non-missing data*. This means you will just use the `.transform()` function. It is important to standardize the new predictors the same way we standardized the original predictors if we want the predictions to make sense. Calling `.fit_transform()` will reset the standardized scale.\n",
    "- Predict what the missing vmail plan values should be.\n",
    "- Replace the missing values in the original with the predicted values.\n",
    "\n",
    "> **Note:** It may predict all 0's. This is OK. If you want to see the predicted probabilities of `vmail_plan` for each row you can use the `.predict_proba()` function instead of `.predict()`.  You can use these probabilities to manually set the criteria threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_miss = impute_missing[impute_cols]\n",
    "X_miss_s = ss.transform(X_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vmail_plan_impute = knn.predict(X_miss_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vmail_plan_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# creating a DF copy to use to imputed missing values\n",
    "churn_imputed = churn.copy()\n",
    "# filling missing vmail_plan values with those predicted by KNN model\n",
    "churn_imputed.loc[churn.vmail_plan.isnull(), 'vmail_plan'] = vmail_plan_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Impute the missing values for `vmail_message` using the same process.\n",
    "\n",
    "Since `vmail_message` is essentially a continuous measure, you need to use `KNeighborsRegressor` instead of the `KNeighborsClassifier`.\n",
    "\n",
    "KNN can do both regression and classification! Instead of \"voting\" on the class like in classification, the neighbors will average their value for the target in regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_k_reg(X, y, k_min=1, k_max=51, step=2, cv=10):\n",
    "    k_range = list(range(k_min, k_max+1, step))\n",
    "    r2s = []\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=cv)\n",
    "        r2s.append(np.mean(scores))\n",
    "    print(np.max(r2s), np.argmax(k_range))\n",
    "    return np.argmax(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# x-true & y-true\n",
    "y = impute_valid.vmail_message.values\n",
    "X = impute_valid[impute_cols]\n",
    "\n",
    "# set and fit the scaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "# call/use find k-best function on known data\n",
    "best_k = find_best_k_reg(Xs, y)\n",
    "\n",
    "# apply k-best to fit model\n",
    "knn = KNeighborsRegressor(n_neighbors=best_k)\n",
    "knn.fit(Xs, y)\n",
    "\n",
    "# prepair rows with missing target values\n",
    "X_miss = impute_missing[impute_cols]\n",
    "X_miss_s = ss.transform(X_miss)\n",
    "\n",
    "# use model to predict unknown values\n",
    "vmail_message_impute = knn.predict(X_miss_s)\n",
    "vmail_message_impute\n",
    "\n",
    "# this r2 is not very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assign predicted values to missing values in dataframe\n",
    "churn_imputed.loc[churn.vmail_message.isnull(), 'vmail_message'] = vmail_message_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Given the accuracy (and $R^2$) of your best imputation models when finding the best K neighbors, do you think imputing is a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The accuracy and R2 are very bad. This our imputed values are most likely wrong with these models.\n",
    "# This doesn't necessarily mean that imputation is a bad idea, but we may want to consider\n",
    "# using a different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. With the imputed dataset, cross-validate the accuracy predicting churn. Is it better? Worse? The same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = churn_imputed[[c for c in churn_nona.columns if not c in ['area_code','state','churn']]]\n",
    "y = churn_imputed.churn.values\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "k_values = list(range(1,50,2))\n",
    "accs = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, Xs, y, cv=10)\n",
    "    accs.append(np.mean(scores))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(k_values, accs, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(np.max(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Its basically exactly the same. \n",
    "# However the peak performance comes at about k=9\n",
    "# Given that our model using imputed data scores almost exactly the same\n",
    "# and requires more neighbors to come reach optimal accuracy\n",
    "# we would either want to investigate other means of imputation\n",
    "# or\n",
    "# utilize the original model as it is computationally more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
